{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Kannada MNIST](https://www.kaggle.com/c/Kannada-MNIST/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IW = 28\n",
    "IH = 28\n",
    "TP = 10\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        \n",
    "        root = '../../data/Kannada-MNIST'\n",
    "        sample_file = os.path.join(root, 'sample_submission.csv')\n",
    "        dev_file = os.path.join(root, 'Dig-MNIST.csv')\n",
    "        train_file = os.path.join(root, 'train.csv')\n",
    "        test_file = os.path.join(root, 'test.csv')\n",
    "\n",
    "        for file in [dev_file, sample_file, train_file, test_file]:\n",
    "            assert os.path.exists(file), 'Please download dataset and save to \"data/Kannada-MNIST/\" before boot'\n",
    "\n",
    "        self.X_train, self.Y_train = self.read_csv(train_file, type='train')\n",
    "        self.X_dev, self.Y_dev = self.read_csv(dev_file, type='dev')\n",
    "        self.X_test, _ = self.read_csv(test_file, type='test')\n",
    "        self.num_train_data, self.num_dev_data, self.num_test_data = self.X_train.shape[0], self.X_dev.shape[0], self.X_test.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def read_csv(file_path, type='train'):\n",
    "        \"\"\" 读取 csv 数据 \"\"\"\n",
    "        X = []\n",
    "        Y = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                print(f'get data {i}', end='\\r')\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                line = line.rstrip()\n",
    "                items = line.split(',')\n",
    "                if type != 'test':\n",
    "                    Y.append(np.array(items[0], dtype=np.int32))\n",
    "                X.append(np.array(items[1: ], dtype=np.float32).reshape((IH, IW, 1)) / 255.0)\n",
    "\n",
    "        X = np.array(X)\n",
    "        Y = np.eye(TP)[Y] if type != 'test' else None\n",
    "        return X, Y\n",
    "\n",
    "    def random_mini_batches(self, batch_size = 64):\n",
    "        \"\"\" 切分训练集为 mini_batch \"\"\"\n",
    "        \n",
    "        data_size = len(self.X_train)\n",
    "        permutation = list(np.random.permutation(data_size))\n",
    "        batch_permutation_indices = [permutation[i: i + batch_size] for i in range(0, data_size, batch_size)]\n",
    "        for batch_permutation in batch_permutation_indices:\n",
    "            yield self.X_train[batch_permutation], self.Y_train[batch_permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    \"\"\" CNN 模型 \"\"\"\n",
    "    def __init__(self, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        self.flatten = tf.keras.layers.Reshape(target_shape=(7 * 7 * 64,))\n",
    "        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=128, activation=tf.nn.relu)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "        self.dense3 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.dense3(x)\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xception(tf.keras.Model):\n",
    "    \"\"\" Xception 模型 \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=[3, 3],\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        self.separable_conv2 = tf.keras.layers.SeparableConv2D(\n",
    "            filters=32,\n",
    "            kernel_size=[3, 3],\n",
    "            padding='same'\n",
    "        )\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        self.separable_conv3 = tf.keras.layers.SeparableConv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[3, 3],\n",
    "            padding='same'\n",
    "        )\n",
    "        self.pool3 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        self.separable_conv4 = tf.keras.layers.SeparableConv2D(\n",
    "            filters=128,\n",
    "            kernel_size=[3, 3],\n",
    "            padding='same'\n",
    "        )\n",
    "        self.dw_conv = tf.keras.layers.DepthwiseConv2D(\n",
    "            kernel_size=(7, 7),\n",
    "            strides=(1, 1),\n",
    "            padding='valid',\n",
    "        )\n",
    "        #         self.global_average_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.separable_conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        # x = self.separable_conv3(x)\n",
    "        # x = self.pool3(x)\n",
    "        x = self.separable_conv4(x)\n",
    "        x = self.dw_conv(x)\n",
    "        #         x = self.global_average_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 50\n",
    "print_step = 100\n",
    "dev_step = 1000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(dropout_rate=0.1)\n",
    "# model = Xception()\n",
    "data_loader = MNISTLoader()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hots_to_labels(one_hots):\n",
    "    return np.array([[np.argmax(one_hot)] for one_hot in one_hots])\n",
    "\n",
    "def predict(model, data_loader, batch_size=10000, type='train'):\n",
    "    wrongs = 0\n",
    "    data_length = data_loader.num_train_data if type == 'train' else data_loader.num_dev_data\n",
    "    X = data_loader.X_train if type == 'train' else data_loader.X_dev\n",
    "    Y = data_loader.Y_train if type == 'train' else data_loader.Y_dev\n",
    "    for i in range(0, data_length, batch_size):\n",
    "        print(f'predict {i}', end='\\r')\n",
    "        X_batch = X[i: i + batch_size]\n",
    "        Y_batch = Y[i: i + batch_size]\n",
    "        Y_batch_= model.predict(X_batch)\n",
    "        Y_batch, Y_batch_ = one_hots_to_labels(Y_batch), one_hots_to_labels(Y_batch_)\n",
    "        mask = Y_batch.reshape((Y_batch.shape[0], )) - Y_batch_.reshape(Y_batch_.shape[0], )\n",
    "        wrongs += len(np.flatnonzero(mask))\n",
    "    return 1- wrongs / data_length\n",
    "\n",
    "print(predict(model, data_loader, type='dev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_epochs):\n",
    "# for i in range(2):\n",
    "    num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "    for j, (X, Y) in enumerate(data_loader.random_mini_batches(batch_size)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            Y_ = model(X)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
    "                y_true=Y,\n",
    "                y_pred=Y_\n",
    "            ))\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        if (i * data_loader.num_train_data + j * batch_size) % print_step == 0:\n",
    "            print(f\"{i} - {j * batch_size: 6}: loss {loss.numpy()}\")\n",
    "        if (i * data_loader.num_train_data + j * batch_size) % dev_step == 0:\n",
    "            train_accuracy = predict(model, data_loader, type='train')\n",
    "            dev_accuracy = predict(model, data_loader, type='dev')\n",
    "            print(f'train accuracy: {train_accuracy: .2%} dev accuracy: {dev_accuracy: .2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, data_loader, type='dev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
