# Operating System <Badge text="alpha" type="warn"/> <Badge text="4.2.2"/>

## 1 操作系统引论

配置在计算机硬件上的第一层硬件

### 1.1 操作系统的目标和作用

#### 1.1.1 操作系统的目标

-  方便性 避免用户书写机器语言
-  有效性 防止大部分设备处于空闲状态，在操作系统的调度下各部分的协调恰如其分
-  可扩充性 能方便地增添新的功能和模块
-  开放性 按照某些标准开发，以便软硬件的兼容等等

#### 1.1.2 操作系统的作用

-  OS 作为用户与计算机硬件系统之间的接口

   ![OS01](../Images/OS01.png)

-  OS 作为计算机系统资源的管理者

   -  处理器上可执行的指令分为
      -  特权指令
      -  非特权指令
   -  处理器状态划分为
      -  管态（管理态）
      -  目态（用户态）

   > 处理器状态保证了特权指令的正确使用，把 OS 与用户程序区别开来

-  OS 实现了对计算机资源的抽象

#### 1.1.3 推动操作系统发展的主要动力

-  不断提高计算机资源利用率
-  方便用户
-  器件的不断更新换代
-  计算机体系结构的不断发展
-  不断提出新的应用要求

### 1.2 操作系统的发展过程

#### 1.2.1 未配置操作系统的计算机系统

1. 人工操作方式

   人工装填纸带，CPU 大多数时间在等待，浪费了大量的资源

2. 脱机输入/输出（Off-Line I/O）方式

   在手工与 CPU 之间加上了一个磁带，以优化 I/O 与 CPU 速度不匹配的问题

#### 1.2.2 单道批处理系统

-  单道批处理系统（Simple Batch Processing System）的处理过程

   用监督程序来解放装填纸带人员的双手，并进一步解决了 I/O 与 CPU 之间速度不匹配的问题

-  单道批处理系统的特征

   -  单道性 内存中仅有一道程序运行
   -  自动性
   -  顺序性

#### 1.2.3 多道批处理系统

-  多道程序设计的基本概念

   用户提交的作业形成队列，按一定算法将若干作业调入内存

-  多道程序设计的优点

   -  提高 CPU 利用率
   -  提高内存和 I/O 设备利用率
   -  增加系统吞吐量

-  多道程序设计的缺点

   -  平均周转时间长
   -  依然无交互能力

#### 1.2.4 分时系统

-  分时系统产生的动力

   -  人们亟需可以实现**人机交互**的处理机以便调试运行程序
   -  **共享主机**

-  分时系统实现中的关键问题
   -  及时接收 及时接收各个用户终端的输入
   -  及时处理 及时处理用户键入的命令

=> 分时系统，将 CPU 的时间分片，每个作业每次只能运行一个时间片

-  分时系统的特征

   -  多路性
   -  独立性 每个人都好像独占资源
   -  及时性
   -  交互性

#### 1.2.5 实时系统

-  需求

   -  实时控制
   -  实时信息处理

-  实时任务

   -  按任务执行时是否呈现周期性来划分
      -  周期性实时任务
      -  非周期性实时任务
   -  根据对截止时间的要求来划分
      -  硬实时任务
      -  软实时任务

-  实时系统与分时系统特征的比较

   -  多路性
   -  独立性
   -  交互性
   -  及时性
   -  可靠性

#### 1.2.6 微机操作系统的发展

1. 单用户单任务操作系统

   -  CP/M
   -  MS-DOS

2. 单用户多任务操作系统

   各种 Windows

3. 多用户多任务操作系统

   UNIX

   -  Solaris
   -  Linux :heart:

#### 1.2.7 其它操作系统

-  网络操作系统
-  分布式操作系统 可独立也可协同，对用户来说相当于一个操作系统
-  嵌入式操作系统

### 1.3 操作系统的特征

#### 1.3.1 并发性

并行和并发的区别，组原就有提到，并行是真的多处理器处理多数据，并发是利用时分技术实现的，其微观本质上还是串行

为了实现并发，引入了进程的概念，其**作为资源分配的基本单位，可在系统中能独立运行**

为了进一步提高并发程度，在进程内引入了线程，其**作为独立运行和独立调度的基本单位，并不会拥有系统资源，开销就会小很多**

#### 1.3.2 共享性

-  互斥共享技术

   保证各个进程之间不会混淆

-  同时访问方式

   各个进程可以同时访问同一个设备，比如磁盘

#### 1.3.3 虚拟技术

-  时分复用技术
   -  虚拟处理机技术
   -  虚拟设备技术
-  空分复用技术
   -  虚拟磁盘技术 磁盘分区
   -  虚拟存储器技术

#### 1.3.4 异步性

各个进程停停走走……

### 1.4 操作系统的五大功能

#### 1.4.1 处理机管理

-  进程控制
-  进程同步
-  进程通信
-  调度

#### 1.4.2 存储器管理功能

-  内存分配
-  内存保护
-  地址映射
-  内存扩充

#### 1.4.3 设备管理功能

-  缓存管理
-  设备分配
-  设备处理

#### 1.4.4 文件管理功能

-  文件存储空间的管理
-  目录管理
-  文件的读/写管理和保护

#### 1.4.5 操作系统与用户之间的接口

-  用户接口
-  程序接口

#### 1.4.6 现代操作系统的新功能

-  系统安全
-  网络的功能和服务
-  支持多媒体

### 1.5 OS 结构设计

#### 1.5.1 传统的操作系统结构

1. 无结构操作系统
2. 模块化结构操作系统 分解成一个一个模块
3. 分层式结构 OS 有序分层

#### 1.5.2 客户/服务器（C/S）模式简介

便于集中管理，但会有瓶颈问题和不可靠性

#### 1.5.3 面向对象的程序设计（OOP）简介

#### 1.5.4 微内核 OS 结构

-  足够小的内核

   将操作系统中最基本的部分放入微内核，其他部分放在外面作为服务器

-  基于 C/S 模式

   ![OS02](../Images/OS02.png)

-  应用”机制与策略分离“原理
-  采用面向对象技术

## 2 进程管理

### 2.1 进程的基本概念

#### 2.1.1 程序的顺序执行及其特征

-  程序的顺序执行是指程序可以保证其按照其顺序执行

-  特征
   -  顺序性
   -  封闭性
   -  可再现性

#### 2.1.2 程序的并发执行及其特征

-  多道程序并发执行

-  特征
   -  间断性
   -  失去封闭性
   -  不可再现性 （资源共享，可能使用时被其他程序所修改）

#### 2.1.3 进程的特征与状态

![OS04](../Images/OS04.png)

-  定义

   -  进程是程序的一次执行
   -  进程是一个程序及其数据在处理机上顺序执行时所发生的活动
   -  进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位

-  特征

   -  结构性
   -  动态性
   -  并发性
   -  独立性
   -  异步性

-  状态

   -  活动进程的三种状态
      -  就绪
      -  执行
      -  阻塞
   -  另外两种状态
      -  创建
      -  终止
   -  挂起状态（将进程内存 $\to$ 外存）

   ![OS03](../Images/OS03.png)

   > N 核 CPU ，共有 M 个进程
   >
   > -  就绪态用户进程最多几个？最少几个？
   > -  M-N, 0
   > -  执行态用户进程最多几个？最少几个？
   > -  N, 0
   > -  阻塞态用户进程最多几个？最少几个？
   > -  M, 0

#### 2.1.4 进程控制块 PCB

系统是根据进程的 PCB 感知到该进程的存在的,PCB 是进程存在的**唯一标志**，因此系统总是通过 PCB 对进程进行控制的

-  PCB 中的信息

   -  进程标识信息
      -  内部标识号 PID ，操作系统分配
      -  外部标识号 由字母数字组成的，创建者提供
   -  处理机状态信息
      -  通用寄存器
      -  指令计数器
      -  程序状态字 PSW
      -  用户栈指针
   -  进程调度信息
      -  进程状态
      -  进程优先级
      -  进程调度所需的其它信息
      -  事件
   -  进程控制信息
      -  程序和数据的地址
      -  进程同步和通信机制
      -  资源清单
      -  链接指针（当然，索引方式应该是没有的）

-  PCB 组织方式

   -  链接方式 组织成链表

      ![OS05](../Images/OS05.png)

   -  索引方式 额外建立一个索引表，更快，但是额外消耗一部分内存

      ![OS06](../Images/OS06.png)

### 2.2 进程控制

通过**原语**来实现

原语是原子操作，是不可分割的基本单位，要么全做、要么全不做

#### 2.2.1 进程的创建

-  进程图

   是一种树状的家族关系，子进程继承父进程资源，如 UNIX

   > Windows 不是这种关系，Win 的各个进程之间是平等的，并不是层次关系，进程之间的关系是通过获取句柄来调节的

-  引起创建进程的事件

   -  用户登录
   -  作业调度
   -  提供服务
   -  应用请求

-  进程的创建原语（Create）
   -  申请空白 PCB
   -  为新进程分配资源
   -  初始化 PCB
   -  将新进程插入就绪队列

#### 2.2.2 进程的终止

-  引起进程终止的事件

   -  正常结束
   -  异常结束
      -  越界错
      -  保护错
      -  非法指令
      -  特权指令错
      -  运行超时
      -  等待超时
      -  算术运算错
      -  I/O 故障
   -  外界干预
      -  操作员或操作系统干预
      -  父进程请求
      -  父进程中止

-  进程的终止原语（termination）
   -  根据被终止进程的标识符，检索出 PCB ，读取进程状态
   -  若处于执行状态，则立即终止
   -  若还有子孙进程，则递归终止
   -  将资源归还其父进程或者系统
   -  将被终止进程 PCB 从所在队列中移出

#### 2.2.3 进程的阻塞与唤醒

-  引起进程阻塞和唤醒的事件

   -  请求系统服务
   -  启动某种操作
   -  新数据尚未到达
   -  无新工作可做

-  进程阻塞原语（block）
-  进程唤醒原语（wakeup）

#### 2.2.4 进程的挂起和激活

-  进程挂起原语（suspend）
-  进程激活原语（active）

### 2.3 进程同步

[本章节 Python 实现](https://github.com/SigureMo/notev/tree/master/Codes/OS/process_sync)

#### 2.3.1 进程同步的基本概念

-  两种形式的制约关系
   -  间接相互制约关系（互斥） 多个进程共享系统资源
   -  直接相互制约关系（同步） 多个进程之间共同访问缓冲区

问题的根源就在于 临界资源

-  临界资源 就是发生冲突的部分 比如共享的系统资源（硬件临界资源）、共享的缓冲区（软件临界资源）

-  临界区 每个进程中访问临界资源的那段*代码*，我们将一个访问临界资源的循环进程描述如下

   ```
   while (TRUE) {
      进入区（entry section）
      临界区（critical section）
      退出区（exit section）
      剩余区（remainder section）
   }
   ```

   各进程对自己的临界区访问是互斥的

-  同步机制应遵循的规则
   -  空闲让进
   -  忙则等待
   -  有限等待
   -  让权等待

#### 2.3.2 硬件同步机制

-  关中断 但是会引发一系列问题
-  利用 Test-and-Set 指令实现互斥 将“测试并建立”作为一条原语
-  利用 Swap 指令实现进程互斥 使用 lock 和 key 两个变量

他们虽然都实现了互斥，但是都有一个很大的问题，就是尝试访问资源是连续测试的（如 `while TS(&lock);`），仍然浪费 CPU 资源，不符合“让权等待”原则

#### 2.3.3 信号量机制

-  整型信号量

   ```c
   wait(S) {
       while (S <= 0>);
       S--;
   }

   signal(S) {
       S++;
   }
   ```

   问题当然是，还是不符合“让权等待”原则

-  记录型信号量

   ```c
   typedef struct {
       int value;
       struct process_control_block *list;
   } semaphore;

   wait (semaphore *S) {
       S->value--;
       if (S->value < 0) block(S->list);
   }

   signal(semaphore *S) {
      S->value++;
      if (S->value <= 0) wakeup(S->list);
   }
   ```

   与前面不同的是，我们现在定义了一个数据结构，增加了一个列表，这个列表干嘛呢？

   由于我们要在无法获取资源的时候将 CPU 资源让出去，所以 while 轮询是不可行的了，我们可以使用 block 原语将自己阻塞起来，等到有资源的时候让别人唤醒自己，当然，为了保证别人能唤醒自己，就要把自己存储到一个列表中，就是我们新的数据结构中的那个列表啦

   另外，我们可以将 value 当做资源数，初始化的数量就是资源的总数量

-  AND 型信号量

   当一个进程需要多个资源才能执行怎么办呢？比如进程一二都需要资源一二，进程一请求资源一成功，进程二请求资源二成功，这时候进程一继续请求资源二，把自己阻塞起来了，进程二请求资源一，也把自己阻塞起来了，结果……死锁了……

   如何解决？如果我们将某个进程请求一系列资源作为一个原语就可以啦，这样就不需要担心请求一部分另一部分没请求到的问题啦，这时候使用 `Swait(S1, S2, ..., Sn)` 和 `Ssignal(S1, S2, S3, ..., Sn)` ， `S1` 到 `Sn` 表示该进程所需要的所有资源

-  信号量集

   在 AND 型信号量的基础上增加 $t_i$ 和 $d_i$ ，$t_i$ 表示资源的分配下限值，$S_i \geq t_i$ 才予以分配，$d_i$ 表示资源的需求量，对应格式变为 - $Swait(S_1, t_1, d_1, \cdots, S_n, t_n, d_n)$ - $Ssignal(S_1,d_1, \cdots, S_n, d_n)$

   有以下几个特殊用法：

   -  `Swait(S, d, d)` 每次申请 d 个资源，低于 d 个不予申请
   -  `Swait(S, 1, 1)` 一般的记录型信号量
   -  `Swait(S, 1, 0)` $S \geq 1$ 时，允许多个进程进入特定区， $S = 0$ 时，将阻止任何进程进入特定区

   > 有个细节需要注意下，就是 `Swait` 结束后被唤醒并不能直接进入临界区，还需要重新尝试请求资源，因为这个时候并不能保证所有资源都就绪，而 `wait` 只需要一个资源，这就保证了被唤醒后资源一定全部就绪，所以可以直接进入临界区

#### 2.3.4 信号量的应用

-  使用信号量实现互斥

   （两个进程为例）使用 mutex 作为互斥信号量，它可以取 `{-1, 0, 1}` ，初始化为 1 > - mutex = 1，表示两个进程均未进入临界区 > - mutex = 0，表示一个进程进入临界区 > - mutex = -1，表示一个进程进入临界区，另一个尝试进入临界区失败，阻塞并存入队列

   为了实现互斥，就需要两个进程进入临界区前调用 `wait(mutex)` ，出临界区后调用 `signal(mutex)`，否则会引发错误

-  利用信号量实现前趋关系

   如何保证一个进程运行到命令 B 的时候另一个进程已经将命令 A 运行完了？比如一个进程要读取另一个进程写完的文件，怎么保证在这之前另一进程写操作已经完成？

   仍然使用这个套路，不过将 mutex 初值置为 0 ，我们在后继任务*前*调用 `wait(mutex)` ，在前趋任务完成*后*调用 `signal(mutex)` ，这样就可以保证后继任务先到达的话会阻塞，而前趋任务完成后，就会“通知”后继任务可以开始做啦

-  管程机制

   是使用面向对象将共享变量、条件变量以及各种方法等等封装起来，同时只能有一个进程进入管程，这就保证了对临界资源的访问是互斥的

   当调用管程的进程被阻塞时，其它进程也就不能进入管程使用资源，为了解决该问题，管程内设了条件变量，当进程因为条件 x 而发生阻塞时，进程调用 `x.wait` 方法，将自己加入阻塞队列，直到条件 x 发生了变化，其它进程（当时正在管程内的进程）调用 `x.signal` 将队列 x 下的进程唤醒

### 2.4 经典进程的同步问题

#### 2.4.1 生产者-消费者问题

[PC.py](https://github.com/SigureMo/notev/blob/master/Codes/OS/process_sync/PC.py)

-  使用记录型信号量解决该问题

   -  生产者先后使用 `wait(empty)` `wait(mutex)` `signal(mutex)` `signal(full)`
   -  消费者先后使用 `wait(full)` `wait(mutex)` `signal(mutex)` `signal(empty)`

   > 注意 `wait` 的先后顺序，如果 `wait(mutex)` `wait(empty)` 可以想象下满了或者空的情况，会出现死锁……

-  利用 AND 信号量解决该问题

   -  生产者先后使用 `Swait(empty, mutex)` `Ssignal(mutex, full)`
   -  消费者先后使用 `Swait(full, mutex)` `Ssignal(mutex, empty)`

   解决死锁问题

-  利用管程解决该问题

   定义好管程内要做的，生产者用 `PC.put(x)`， 消费者用 `PC.get(x)` 即可

> 一些变体
>
> -  缓冲区无限大，那么我们就不需要 `wait(empty)` `signal(empty)` 了
> -  生产者生产者互斥、消费者消费者互斥，但生产者消费者不互斥，我们只需要设两个互斥信号量即可

#### 2.4.2 哲学家进餐问题

[The_Dining_Philosophers.py](https://github.com/SigureMo/notev/blob/master/Codes/OS/process_sync/The_Dining_Philosophers.py)

-  利用记录型信号量解决该问题

   防止他们同时拿起左侧筷子造成的死锁，需要有一定的改进方案

-  利用 AND 信号量机制解决该问题

   很容易想到这个方法解决上述问题

#### 2.4.3 读者-写者问题

[Writer_and_Reader.py](https://github.com/SigureMo/notev/blob/master/Codes/OS/process_sync/Writer_and_Reader.py)

需要注意的是，当一个 Writer 进程在写的时候，不允许任何 Reader 进程和 Writer 进程访问该对象

但是要怎么实现呢？

-  写者的话，直接用一个互斥信号量 `wmutex` 就好了
-  读者需要考虑的比较多
   -  首先，读者之间是不互斥的，我们是要解决读者使写者不能读的问题，所以当读者在读的时候， `wait(wmutex)`
   -  但是，如果直接 `wait(wmutex)` 的话，所有“者”都互斥了，可是多个读者是可以同时读的
   -  我们判断下是否已经有人在读了，当无人在读的情况下也就是第一个读者才 `wait(wmutex)`，相应地，最后一个读者才 `signal(wmutex)`
   -  为了判断读者数量，额外引进了一个变量，这个变量会成为临界资源，所以需要使用 `rmutex` 包裹，以保证读者读写该变量时互斥

另外，可以利用信号量集以更巧妙的方法实现（注意 `Swait(S, 1, 0)`，只检查资源，不消耗）

[Writer_and_Reader.py](https://github.com/SigureMo/notev/blob/master/Codes/OS/process_sync/Writer_and_Reader_SemSet.py)

#### 2.4.4 其他问题（习题）

-  [购物问题 Shopping.py](https://github.com/SigureMo/notev/blob/master/Codes/OS/process_sync/Shopping.py)
-  [进程同步 Processes.py](https://github.com/SigureMo/notev/blob/master/Codes/OS/process_sync/Processes.py)
-  [独木桥问题 Single-plank_Bridge.py](https://github.com/SigureMo/notev/blob/master/Codes/OS/process_sync/Single-plank_Bridge.py)

### 2.5 进程通信

-  共享存储器系统

   -  基于共享数据结构的通信方式
   -  基于共享存储区的通信方式 中等信息传递，用户解决同步问题

-  管道(pipe)通信系统 大量信息传递，系统解决同步问题
-  消息传递系统 少量信息传递，系统解决同步问题
-  客户机-服务器系统
   -  socket
   -  RPC

### 2.6 线程的基本概念

#### 2.6.1 线程与进程的对比

-  调度的基本单位 切换开销小
-  并发性 线程之间也可以并发执行
-  拥有资源 并不拥有系统额外分配的资源，享有父进程的资源，故创建开销小
-  独立性 同一进程的不同线程之间可以共享资源，独立性不明显
-  系统开销 创建与切换都远比进程快
-  支持多处理机系统 一个进程的多个线程可在多个核心上运行，这使得多个线程之间实现了真的并行，大大提高了该进程的完成速度

#### 2.6.2 线程的状态和线程控制块

-  线程的三个状态 和进程一样 **执行**、**就绪**、**阻塞**
-  线程控制块 TCB 类似于 PCB

### 2.7 线程的实现

#### 2.7.1 线程的实现方式

-  内核支持线程 KST

   内核所“承认”的线程，可获得内核分配的 CPU 时间片，也可在多核 CPU 上实现并行

   -  优点
      -  更轻量的结构
      -  进程中一个线程阻塞后，其余线程可正常运行
      -  多核心可并发执行

-  用户级线程 ULT

   使用函数库就可以实现，内核并不知道用户级线程的存在，所以内核给它分配的时间片是按其父进程分配的，各个线程将争夺进程的时间片执行

   -  优点
      -  线程切换不需要到内核空间（不需要用户态与核心态的切换）
      -  调度算法可以是进程专用的
      -  用户级线程的实现与 OS 平台无关

-  组合方式

   用户级线程与内核支持线程的组合（多对一、一对一、多对多）

![OS07](../Images/OS07.png)

## 3 处理机调度与死锁

### 3.1 处理机调度的层次

| 调度程序         | 调度对象           | 分配资源   | 调度频率 | 适宜的调度算法                                         |
| ---------------- | ------------------ | ---------- | -------- | ------------------------------------------------------ |
| 长程调度（作业） | 后备作业           | 内存、设备 | 低       | 资源搭配、先进先出、优先数、短作业优先、最高响应比优先 |
| 中程调度（交换） | 就绪进程、等待进程 | 内存、外存 | 中       | 优先算法、FIFO                                         |
| 短程调度（进程） | 就绪进程、就绪线程 | CPU        | 高       | 轮转法、多级反馈                                       |

#### 3.1.1 高级调度

-  作业 = JCB + 作业说明书 + 程序 + 数据

-  作业步 作业的各个相对独立步骤

-  作业控制块 JCB

-  调度算法
   -  先来先服务算法
   -  短作业优先调度算法
   -  响应比高者优先的调度算法 综合考虑上面两种算法
   -  基于作业优先级的调度算法

#### 3.1.2 低级调度

-  基本机制

   -  排队器
   -  分派器
   -  上下文切换机制 （两对上下文切换操作）

-  进程调度方式
   -  非抢占方式
   -  抢占方式（按一定原则抢占 CPU）
      -  优先权原则
      -  短作业（进程）优先原则
      -  时间片原则

#### 3.1.3 中级调度

将内存上的进程转换到外存上或相反的过程，也就是进程的挂起与唤醒，提高了内存的利用率

### 3.2 调度队列模型和调度准则

#### 3.2.1 调度队列模型

-  仅有进程调度的调度队列模型
-  具有高级和低级调度的调度队列模型
-  同时具有三级调度的调度队列模型

   ![OS08](../Images/OS08.png)

#### 3.2.2 选择调度方式和调度算法的若干原则

-  面向用户的原则

   -  周转时间快 （使用平均周转时间评估）
   -  响应时间快
   -  截止时间的保证
   -  优先权准则

-  面向系统的准则
   -  系统吞吐量高
   -  处理机利用率好
   -  各类资源的平衡利用

### 3.3 调度算法

-  周转时间：作业等待的时间
-  带权周转时间：周转时间 / 服务时间

#### 3.3.1 先来先服务算法

很明显， FCFS 的周转时间会很长

#### 3.3.2 短作业（进程）优先调度算法

SJF 算法极大地提高了系统吞吐量，但是会出现长作业长期不被调度的情况

#### 3.3.3 高优先权优先调度算法

-  优先权调度算法的类型

   -  非抢占式优先权算法
   -  抢占式优先权调度算法

-  优先权的类型

   -  静态优先权 不可改变的
   -  动态优先权 可随着进程的等待时间而改变，我们可以规定，在就绪队列的进程，随其等待时间的增长，其优先权以速率 a 提高

-  高响应比优先调度算法

   优先权 = (等待时间 + 要求服务时间) / 要求服务时间

#### 3.3.4 基于时间片的轮转调度算法

-  时间片大小的确定

   -  时间片太大会使得算法退化，时间片太小会增大切换上下文的开销，故可以取略大于一次典型交互所需要的时间作为时间片

#### 3.3.5 多队列调度算法

分成不同的队列，为不同就绪队列设置不同的调度算法

![OS09](../Images/OS09.png)

#### 3.3.6 多级反馈队列调度算法

-  设置多个就绪队列
-  为每个队列设置一个优先级
-  仅当优先级高的队列空闲时才能调度优先级低的队列

### 3.4 实时调度

#### 3.4.1 实现实时调度的基本条件

-  提供必要的信息 就绪时间等等
-  系统处理能力强
-  采用抢占式调度机制
-  具有快速切换机制

#### 3.4.2 实时调度算法的分类

-  非抢占式调度算法
   -  非抢占式轮转调度算法
   -  非抢占式优先调度算法 将实时任务放在队首
-  抢占式调度算法
   -  基于时钟中断的抢占式优先权调度算法 时钟周期的整数倍时刻才能抢占
   -  立即抢占的优先权调度算法

### 3.5 产生死锁的原因和必要条件

#### 3.5.1 产生死锁的原因

-  竞争资源（竞争非剥夺性资源） 资源数量不足需求 形成**环路**

   ![OS10](../Images/OS10.png)

-  进程间推进顺序非法

#### 3.5.2 产生死锁的必要条件

-  互斥条件
-  请求和保持条件 所需资源使用完之前不释放已有资源
-  不剥夺条件 只能主动释放资源，其他人不可抢占
-  环路等待条件 发生死锁时，必然存在资源的环路链

#### 3.5.3 处理死锁的基本方法

-  预防死锁
-  避免死锁
-  检测死锁
-  解除死锁

### 3.6 预防死锁

由于死锁时必要条件一定满足，所以破坏了死锁的必要条件就可以防止死锁，当然，互斥条件我们不应该破坏，因为我们需要它来保证进程的同步问题

#### 3.6.1 摒弃“请求和保持”条件

由动态分配改为静态分配，在所有进程运行之前一次性将所有所需资源申请下来

但是，这大大降低了资源的利用率

#### 3.6.2 摒弃“不剥夺”条件

新的资源请求会剥夺已占有的资源

很复杂很复杂，打印机写一半怎么处理呢？增加了系统开销

#### 3.6.3 摒弃“环路等待”条件

资源有序分配，将各个资源标号，每次申请资源都要按序号递增的次序来申请，避免了环路的产生

> 比如一个进程已经拥有了一个序号比较高的资源，此时想申请序号比较低的资源的话，必须先释放序号比较高的资源

相比前两种是比较好的策略，但仍有一些不足，比如序号的分配等等问题

### 3.7 避免死锁

#### 3.7.1 系统安全状态

如果为进程分配资源后系统会进入不安全状态，那么就不给它分配资源

所谓**安全状态**，就是指系统**存在**某种进程顺序来为每个进程分配其所需资源，使得所有进程都能顺利完成，否则即为不安全状态

> 当然，不安全状态只是不安全，可能发生死锁，并不是一定发生死锁，而安全状态保证了不会发生死锁

-  Example

   | 进程号 | 总共需求 | 已分配 | 还需 | 剩余 |
   | ------ | -------- | ------ | ---- | ---- |
   | P1     | 10       | 5      | 5    | 3    |
   | P2     | 4        | 2      | 2    |      |
   | P3     | 9        | 2      | 7    |      |

   很明显，存在安全序列 \<P2, P1, P3\> 使得进程全部执行完毕

   那么，P3 申请一个资源的话，我们要不要给呢？

   首先，**假如**分配的话，会变成如下状态

   | 进程号 | 总共需求 | 已分配 | 还需 | 剩余 |
   | ------ | -------- | ------ | ---- | ---- |
   | P1     | 10       | 5      | 5    | 2    |
   | P2     | 4        | 2      | 2    |      |
   | P3     | 9        | 3      | 6    |      |

   嗯，找不出来那样的一个序列了，也就是系统会进入不安全状态，所以，拒绝！不给分配！

#### 3.7.2 利用银行家算法避免死锁

（万能的 Dijkstra）

-  银行家算法中的数据结构

   n 为进程数， m 为资源数

   -  可利用资源向量 Available ($m$)
   -  最大需求矩阵 Max ($n \times m$)
   -  分配矩阵 Allocation ($n \times m$)
   -  需求矩阵 Need ($n \times m$)

> 具体算法的话，就是上面例子里的一个资源换成多个资源就好啦

### 3.8 死锁的检测与解除

#### 3.8.1 死锁的检测

由于死锁的预防的资源利用率太低，而死锁的避免又消耗了大量的计算资源来实现，所以在死锁发生的并不频繁的情况下，可以使用死锁的检测 + 解除，当然，我们可以选择在 CPU 利用率比较低的时候才检测，以降低对 CPU 的使用

-  资源分配图

与前面的环路图是一样的，只不过这里资源结点可以代表多个资源，进程指向资源仍旧代表进程请求资源，资源指向进程仍旧代表资源以分配给该进程，只不过每条线代表一个资源

![OS11](../Images/OS11.png)

我们可以尝试通过对资源分配图进行简化来判断是否发生死锁，非死锁情况下资源分配图可简化为各个独立的结点

#### 3.8.2 死锁的解除

-  剥夺资源 从其他进程剥夺足够数量的资源给死锁进程
-  撤销进程 kill 掉死锁进程

> [作业](https://github.com/SigureMo/notev/tree/master/Codes/OS/process_scheduling_and_deadlocks)

## 4 存储器管理

### 4.1 存储器的层次结构

#### 4.1.1 多级存储器结构

![OS12](../Images/OS12.png)

#### 4.1.1 主存储器与寄存器

嗯……就是主存储器和寄存器……

#### 4.1.2 高速缓存和磁盘缓存

-  高速缓存 Cache

   解决 Memory 与 CPU 速度不匹配的问题

-  磁盘缓存

   解决磁盘 I/O 与 Memory 速度不匹配的问题，使用 Memory 部分空间作为磁盘的缓存区，用于暂存频繁使用的磁盘数据

#### 4.1.3 内存管理

-  内存的分配与回收
   -  直接分配 程序内地址为固定值
   -  静态分配 作业装入内存后地址固定不变
   -  动态分配 作业装入内存后地址可变
-  地址转换
   -  逻辑地址：源程序内的变量等地址经过编译或汇编后生成逻辑地址
   -  物理地址：程序由操作系统装入内存后所指的真实内存地址
-  内存保护
   -  防止进程的数据被非法访问
   -  防止越界
      -  上下界寄存器
      -  基址、限长寄存器
-  内存共享
   -  多个进程共享内存中的同一段信息
-  内存扩充
   -  覆盖 让常用功能常驻内存，非常用功能按需装入
   -  对换 挂起不用的程序段
   -  虚拟存储器 利用程序的局部性原理

### 4.2 程序的装入和链接

#### 4.2.1 程序的装入

> 即上面的三种分配方式

-  绝对装入方式 直接
-  可重定位装入方式
   -  静态重定位 程序执行之前地址转换完毕
   -  动态重定位 程序执行期间进行地址转换

#### 4.2.2 程序的链接

![OS13](../Images/OS13.png)

-  静态链接 程序运行前链接
-  装入时动态链接 运行前将所有可能需要运行的模块装入链接
-  运行时动态链接 运行时按需装入链接

# Amendant Record

1. 190311 #1 Finished
2. 190326 [process_sync](https://github.com/SigureMo/notev/tree/master/Codes/OS/process_sync) Finished
3. 190404 #2 Finished
4. 190418 #3 Finished

# Reference

1. 杨志豪老师课程及其[配套课件](http://faculty.dlut.edu.cn/zhyang_CS/zh_CN/jxzy/749840/content/1641.htm)
2. 《计算机操作系统》 汤小丹 梁红兵 哲凤屏 汤子瀛
